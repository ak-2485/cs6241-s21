{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary notes for 2021-03-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider constraints\n",
    "\n",
    "So far, we have considered *unconstrained* optimization problems.\n",
    "The *constrained* problem is\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) \\mbox{ s.t. } x \\in \\Omega\n",
    "$$\n",
    "where $\\Omega \\subset {\\mathbb{R}}^n$. We usually define $x$ in terms of a\n",
    "collection of constraint equations and inequalities:\n",
    "$$\n",
    "  \\Omega = \\{ x \\in {\\mathbb{R}}^n :\n",
    "  c_i(x) = 0, i \\in \\mathcal{E} \\mbox{ and }\n",
    "  c_i(x) \\leq 0, i \\in \\mathcal{I} \\}.\n",
    "$$\n",
    "We will suppose throughout our discussions that both $\\phi$ and all the\n",
    "functions $c$ are differentiable.\n",
    "\n",
    "If $x_*$ is a solution to the constrained minimization problem, we say\n",
    "constraint $i \\in \\mathcal{I}$ is *active* if $c_i(x) = 0$. Often,\n",
    "the hard part of solving constrained optimization problems is figuring\n",
    "out which constraints are active. From this perspective, the equality\n",
    "constrained problem sits somewhere in difficulty between the\n",
    "unconstrained problem and the general constrained problem.\n",
    "\n",
    "Our treatment of constrained optimization is necessarily brief; but in\n",
    "the next two lectures, I hope to lay out some of the big ideas. Today we\n",
    "will focus on formulations; next time, algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three recipes\n",
    "\n",
    "Most methods for constrained optimization involve a reduction to an\n",
    "unconstrained problem (or subproblem). There are three ways such a\n",
    "reduction might work:\n",
    "\n",
    "-   We might *remove* variables by eliminating constraints.\n",
    "\n",
    "-   We might keep the *same* number of variables and try to fold the\n",
    "    constraints into the objective function.\n",
    "\n",
    "-   We might *add* variables to enforce constraints via the method\n",
    "    of Lagrange multipliers.\n",
    "\n",
    "These approaches are not mutually exclusive, and indeed one often\n",
    "alternates between perspectives in modern optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint elimination\n",
    "\n",
    "The idea of constraint elimination is straightforward. Suppose we want\n",
    "to solve an optimization problem with only equality constraints:\n",
    "$c_i(x) = 0$ for $i \\in \\mathcal{E}$, where $|\\mathcal{E}| < n$ and the\n",
    "constraints are independent – that is, the $|\\mathcal{E}| \\times n$\n",
    "Jacobiam matrix $\\partial c / \\partial x$ has full row rank. Then we can\n",
    "think (locally) of $x$ satisfying the constraints in terms of an\n",
    "implicitly defined function $x = g(y)$ for\n",
    "$y \\in {\\mathbb{R}}^{n-|\\mathcal{E}|}$. If this characterization can be\n",
    "made global, then we can solve the unconstrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(g(y))\n",
    "$$\n",
    "over all $y \\in {\\mathbb{R}}^{n-|\\mathcal{E}|}$.\n",
    "\n",
    "The difficulty with constraint elimination is that it requires that we\n",
    "find a global parameterization of the solutions to the constraint\n",
    "equations. This is usually difficult. An exception is when the\n",
    "constraints are *linear*: \n",
    "$$\n",
    "  c(x) = A^T x - b\n",
    "$$\n",
    "In this case, the feasible set $\\Omega = \\{ x : A^T x - b = 0 \\}$ can be\n",
    "written as $x \\in \\{ x^p + z : z \\in \\mathcal{N}(A) \\}$, where $x^p$ is a\n",
    "*particular solution* and $\\mathcal{N}(A)$ is the null space of $A$.\n",
    "We can find both a particular solution and the null space by doing a\n",
    "full QR decomposition on $A$:\n",
    "$$\n",
    "  A = \\begin{bmatrix} Q_1 & Q_2 \\end{bmatrix}\n",
    "      \\begin{bmatrix} R_1 \\\\ 0 \\end{bmatrix}.\n",
    "$$\n",
    "Then solutions to the constraint equations have the form \n",
    "$$\n",
    "  x = A^\\dagger b + Q_2 y = Q_1 R_1^{-T} b + Q_2 y\n",
    "$$\n",
    "where the first term is a particular solution and the second term gives a\n",
    "vector in the null space.\n",
    "\n",
    "For problems with linear equality constraints, constraint elimination\n",
    "has some attractive properties. If there are many constraints, the\n",
    "problem after constraint elimination may be much smaller. And if the\n",
    "original problem was convex, then so is the reduced problem, and with a\n",
    "better-conditioned Hessian matrix. The main drawback is that we may lose\n",
    "sparsity of the original problem. Constraint elimination is also\n",
    "attractive for solving equality-constrained subproblems in optimization\n",
    "algorithms for problems with linear *inequality* constraints,\n",
    "particularly if those constraints are simple (e.g. elementwise\n",
    "non-negativity of the solution vector).\n",
    "\n",
    "For problems with more complicated equality constraints, constraint\n",
    "elimination is hard. Moreover, it may not be worthwhile; in some cases,\n",
    "eliminating constraints results in problems that are smaller than the\n",
    "original formulation, but are harder to solve.\n",
    "\n",
    "The idea of constraint elimination is not limited to equality\n",
    "constraints: one can also sometimes use an alternate parameterization to\n",
    "convert simple inequality-constrained problems to unconstrained\n",
    "problems. For example, if we want to solve a non-negative optimization\n",
    "problem (all $x_i \\geq 0$), we might write $x_i = y_i^2$, or possibly\n",
    "$x_i = \\exp(y_i)$ (though in this case we would need to let\n",
    "$y_i \\rightarrow -\\infty$ to exactly hit the constraint). But while they\n",
    "eliminate constraints, these re-parameterizations can also destroy nice\n",
    "features of the original problem (e.g. convexity). So while such\n",
    "transformations are a useful part of the computational arsenal, they\n",
    "should be treated as one tool among many, and not always as the best\n",
    "tool available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalties and barriers\n",
    "\n",
    "Constraint elimination methods convert a constrained to an unconstrained\n",
    "problem by changing the coordinate system in which the problem is posed.\n",
    "Penalty and barrier methods accomplish the same reduction to the\n",
    "unconstrained case by changing the function.\n",
    "\n",
    "As an example of a *penalty* method, consider the problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) + \\frac{1}{2\\mu} \\sum_{i\\in \\mathcal{E}}\n",
    "  c_i(x)^2 + \\frac{1}{2\\mu} \\sum_{i \\in \\mathcal{I}} \\max(c_i(x),0)^2.\n",
    "$$\n",
    "When the constraints are violated ($c_i > 0$ for inequality constraints\n",
    "and $c_i \\neq 0$ for equality constraints), the extra terms (penalty\n",
    "terms) beyond the original objective function are positive; and as\n",
    "$\\mu \\rightarrow 0$, those penalty terms come to dominate the behavior\n",
    "outside the feasible region. Hence as we let $\\mu \\rightarrow 0$, the\n",
    "solutions to the penalized problem approach solutions to the original\n",
    "(true) problem. At the same time, as $\\mu \\rightarrow 0$ we have much\n",
    "wilder derivatives of $\\phi$, and the optimization problems become more\n",
    "and more problematic from the perspective of conditioning and numerical\n",
    "stability. Penalty methods also have the potentially undesirable property\n",
    "that if any constraints are active at the true solution, the solutions to\n",
    "the penalty problem tend to converge from *outside* the feasible region.\n",
    "This poses a significant problem if, for example, the original objective function\n",
    "$\\phi$ is undefined outside the feasible region.\n",
    "\n",
    "As an example of a *barrier* method, consider the purely inequality\n",
    "constrained case, and approximate the original constrained problem by\n",
    "the unconstrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) - \\mu \\sum_{i \\in \\mathcal{I}} \\log(-c_i(x)).\n",
    "$$\n",
    "As $c_i(x)$ approaches zero from below, the barrier term\n",
    "$-\\mu \\log (-c_i(x))$ grows rapidly; but at any fixed $x$ in the\n",
    "interior of the domain, the barrier goes to zero as $\\mu$ goes to zero.\n",
    "Hence, as $\\mu \\rightarrow 0$ through positive values, the solution to\n",
    "the barrier problem approaches the solution to the true problem through\n",
    "a sequence of *feasible* points (i.e. approximate solutions that\n",
    "satisfy the constraints). Though the feasibility of the approximations\n",
    "is an advantage over penalty based formulations, interior formulations\n",
    "share with penalty formulations the disadvantage that the solutions for\n",
    "$\\mu > 0$ lie at points with increasingly large derivatives (and bad\n",
    "conditioning) if the true solution has active constraints.\n",
    "\n",
    "There are *exact penalty* formulations for which the solution to the\n",
    "penalized problem is an exact solution for the original problem. Suppose\n",
    "we have an inequality constrained problem in which the feasible region\n",
    "is closed and bounded, each constraint $c_i$ has continuous derivatives,\n",
    "and $\\nabla c_i(x) \\neq 0$ at any boundary point $x$ where constraint\n",
    "$i$ is active. Then the solution to the problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) + \\frac{1}{\\mu} \\sum_i \\max(c_i(x), 0)\n",
    "$$\n",
    "is *exactly* the solution to the original constrained optimization\n",
    "problem for some $\\mu > 0$. In this case, we used a\n",
    "*nondifferentiable* exact penalty, but there are also exact\n",
    "differentiable penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrange multipliers\n",
    "\n",
    "Picture a function $\\phi : {\\mathbb{R}}^n \\rightarrow {\\mathbb{R}}$; if\n",
    "you’d like to be concrete, let $n = 2$. Absent a computer, we might\n",
    "optimize of $\\phi$ by the physical experiment of dropping a tiny ball\n",
    "onto the surface and watching it roll downhill (in the steepest descent\n",
    "direction) until it reaches the minimum. If we wanted to solve a\n",
    "constrained minimization problem, we could build a great wall between\n",
    "the feasible and the infeasible region. A ball rolling into the wall\n",
    "would still roll freely in directions tangent to the wall (or away from\n",
    "the wall) if those directions were downhill; at a constrained miminizer,\n",
    "the force pulling the ball downhill would be perfectly balanced against\n",
    "an opposing force pushing into the feasible region in the direction of\n",
    "the normal to the wall. If the feasible region is $\\{x : c(x) \\leq 0\\}$,\n",
    "the normal direction pointing inward at a boundary point $x_*$\n",
    "s.t. $c(x_*) = 0$ is proportional to $-\\nabla c(x_*)$. Hence, if $x_*$\n",
    "is a constrained minimum, we expect the sum of the “rolling downhill”\n",
    "force ($-\\nabla \\phi$) and something proportional to $-\\nabla c(x_*)$ to\n",
    "be zero: \n",
    "$$\n",
    "  -\\nabla \\phi(x_*) - \\mu \\nabla c(x_*) = 0.\n",
    "$$\n",
    "The *Lagrange multiplier* $\\mu$ in this picture represents the magnitude of the\n",
    "restoring force from the wall balancing the tendency to roll downhill.\n",
    "\n",
    "More abstractly, and more generally, suppose that we have a mix of\n",
    "equality and inequality constraints. We define the *Lagrangian* \n",
    "$$\n",
    "  L(x, \\lambda, \\mu) = \\phi(x) +\n",
    "    \\sum_{i \\in \\mathcal{E}} \\lambda_i c_i(x) +\n",
    "    \\sum_{i \\in \\mathcal{I}} \\mu_i c_i(x).\n",
    "$$\n",
    "The *Karush-Kuhn-Tucker (KKT) conditions* for $x_*$ to be a constrained minimizer are\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\nabla_x L(x_*) &= 0 \\\\\n",
    "  c_i(x_*) &= 0, \\quad i \\in \\mathcal{E}\n",
    "  & \\mbox{equality constraints}\\\\\n",
    "  c_i(x_*) & \\leq 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{inequality constraints}\\\\\n",
    "  \\mu_i & \\geq 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{non-negativity of multipliers}\\\\\n",
    "  c_i(x_*) \\mu_i &= 0, \\quad i \\in \\mathcal{I}\n",
    "  & \\mbox{complementary slackness}\n",
    "\\end{aligned}$$ \n",
    "where the (negative of) the “total force” at $x_*$ is \n",
    "$$\n",
    "  \\nabla_x L(x_*) = \\nabla \\phi(x_*) +\n",
    "    \\sum_{i\\in \\mathcal{E}} \\lambda_i \\nabla c_i(x_*) +\n",
    "    \\sum_{i\\in \\mathcal{I}} \\mu_i \\nabla c_i(x_*).\n",
    "$$\n",
    "The complementary slackness condition corresponds to the idea that a multiplier \n",
    "should be nonzero only if the corresponding constraint is active (a “restoring\n",
    "force” is only present if our test ball is pushed into a wall).\n",
    "\n",
    "Like the critical point equation in the unconstrained case, the KKT\n",
    "conditions define a set of (necessary but not sufficient) nonlinear\n",
    "algebraic equations that must be satisfied at a minimizer. Because of\n",
    "the multipliers, we have *more* variables than were present in the\n",
    "original problem. However, the Jacobian matrix (KKT matrix)\n",
    "$$\n",
    "  J = \\begin{bmatrix}\n",
    "    \\nabla^2_x L(x_*) & \\nabla c \\\\\n",
    "    (\\nabla c)^T & 0\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "has a saddle point structure even when $\\nabla^2_x \\phi$\n",
    "is positive definite. Also, unlike the penalty and barrier approaches\n",
    "described before, the Lagrange multiplier approach requires that we\n",
    "figure out which multipliers are active or not — an approach that seems\n",
    "to lead to a combinatorial search in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lay of the Land\n",
    "\n",
    "As we mentioned before, problems with *inequality* constraints tend\n",
    "to be more difficult than problems with *equality* constraints\n",
    "alone, because it involves the combinatorial subproblem of figuring out\n",
    "which constraints are *active* (a constraint $c_i(x) \\leq 0$ is\n",
    "active if $c_i(x) = 0$ at the optimum). Once we have figured out the set\n",
    "of active constraints, we can reduce an inequality-constrained problem\n",
    "to an equality-constrained problem. Hence, the purely\n",
    "equality-constrained case is an important subproblem for\n",
    "inequality-constrained optimizers, as well as a useful problem class in\n",
    "its own right.\n",
    "\n",
    "For problems with only equality constraints, there are several standard\n",
    "options:\n",
    "\n",
    "-   *Null space methods* deal with linear equality constraints by\n",
    "    reducing to an unconstrained problem in a lower-dimensional space.\n",
    "\n",
    "-   *Projected gradient methods* deal with simple equality\n",
    "    constraints by combining a (scaled) gradient step and a projection\n",
    "    onto a constraint set.\n",
    "\n",
    "-   *Penalty methods* approximately solve an equality-constrained\n",
    "    problem through an unconstrained problem with an extra term that\n",
    "    penalizes proposed soutions that violate the constraints. That is,\n",
    "    we use some constrained minimizer to solve\n",
    "    $$\n",
    "      \\mbox{minimize } \\phi(x) + \\frac{1}{\\mu} \\sum_{i \\in\\mathcal{E}} c_i(x)^2.\n",
    "    $$\n",
    "    As $\\mu \\rightarrow 0$, the minimizers to these approximate problems\n",
    "    approach the true minimizer, but the Hessians that we encounter\n",
    "    along the way become increasingly ill-conditioned (with condition\n",
    "    number proportional to $\\mu^{-1}$).\n",
    "\n",
    "-   *KKT solvers* directly tackle the first-order optimality\n",
    "    conditions (the KKT conditions), simultaneously computing the\n",
    "    constrained minimizer and the associated Lagrange multipliers.\n",
    "\n",
    "-   *Augmented Lagrangian* methods combine the advantages of penalty\n",
    "    methods and the advantages of the penalty formulation. In an\n",
    "    augmented Lagrangian solver, one finds critical points for the\n",
    "    augmented Lagrangian \n",
    "    $$\n",
    "      \\mathcal{L}(x, \\lambda; \\mu) =\n",
    "        \\phi(x) + \\frac{1}{\\mu} \\sum_{i \\in \\mathcal{E}} c_i(x)^2 + \\lambda^T c(x)\n",
    "    $$\n",
    "    by alternately adjusting the penalty parameter $\\mu$ and the\n",
    "    Lagrange multipliers.\n",
    "\n",
    "In the inequality-constrained case, we have\n",
    "\n",
    "-   *Active set methods* solve (or approximately solve) a sequence\n",
    "    of equality-constrained subproblems, shuffling constraints into and\n",
    "    out of the proposed working set along the way. These methods are\n",
    "    particularly attractive when one has a good initial estimate of the\n",
    "    active set.\n",
    "\n",
    "-   *Projected gradient methods* deal with simple inequality\n",
    "    constraints by combining a (scaled) gradient step and a projection\n",
    "    onto a constraint set.\n",
    "\n",
    "-   *Barrier methods* and *penalty methods* add a term to the\n",
    "    objective function in order to penalize constraint violations or\n",
    "    near-violations; as in the equality-constrained case, a parameter\n",
    "    $\\mu$ governs a tradeoff between solution quality and conditioning\n",
    "    of the Hessian matrix.\n",
    "\n",
    "-   *Interior point methods* solve a sequence of barrier subproblems\n",
    "    using a continuation strategy, where the barrier or penalty\n",
    "    parameter $\\mu$ is the continuation parameter. This is one of the\n",
    "    most popular modern solver strategies, though active set methods may\n",
    "    show better performance when one “warm starts” with a good initial\n",
    "    guess for the solution and the active set of constraints.\n",
    "\n",
    "As with augmented Lagrangian strategies in the equality-constrained\n",
    "case, state-of-the art strategies for inequality-constrained problems\n",
    "often combine approaches, using continuation with respect to a barrier\n",
    "parameters as a method of determining the active set of constraints in\n",
    "order to get to an equality-constrained subproblem with a good initial\n",
    "guess for the solution and the Lagrange multipliers.\n",
    "\n",
    "The *sequential quadratic programming* (SQP) approach for nonlinear\n",
    "optimization solves a sequence of linearly-constrained quadratic\n",
    "optimization problems based on Taylor expansion of the objective and\n",
    "constraints about each iterate. This generalizes simple Newton iteration\n",
    "for unconstrained optimization, which similarly solves a sequence of\n",
    "quadratic optimization problems based on Taylor expansion of the\n",
    "objective. Linearly-constrained quadratic programming problems are hence\n",
    "an important subproblem in SQP solvers, as well as being an important\n",
    "problem class in their own right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic programs with equality constraints\n",
    "\n",
    "We begin with a simple case of a quadratic objective and linear equality\n",
    "constraints: \n",
    "$$\\begin{aligned}\n",
    "  \\phi(x) &= \\frac{1}{2} x^T H x - x^T d \\\\\n",
    "  c(x) &= A^T x-b = 0,\n",
    "\\end{aligned}$$\n",
    "where $H \\in {\\mathbb{R}}^{n \\times n}$ is symmetric and positive definite\n",
    "*on the null space of $A^T$* (it may be indefinite or singular\n",
    "overall), $A \\in {\\mathbb{R}}^{n \\times m}$ is full rank with $m < n$,\n",
    "and $b \\in {\\mathbb{R}}^m$. Not only are such problems useful in their\n",
    "own right, solvers for these problems are also helpful building blocks\n",
    "for more sophisticated problems — just as minimizing an unconstrained\n",
    "quadratic can be seen as the starting point for Newton’s method for\n",
    "unconstrained optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a test problem for linearly-constrained QP (2D so that we can plot)\n",
    "H = [4.0  1.0 ;\n",
    "     1.0  4.0 ]\n",
    "d = [0.5 ; -2.0]\n",
    "A = [1.0 ; 1.0]\n",
    "b = [1.0]\n",
    "\n",
    "ϕ1(xy) = xy'*H*xy/2 - xy'*d\n",
    "c1(xy) = A'*x - b\n",
    "\n",
    "xx = range(-3, 3, length=100)\n",
    "plot(xx, xx, (x,y) -> ϕ1([x; y]), st=:contour, legend=false)\n",
    "plot!(xx, 1.0 .- xx, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint elimination (linear constraints)\n",
    "\n",
    "As discussed last time, we can write the space of solutions to the\n",
    "constraint equations in terms of a (non-economy) QR decomposition of\n",
    "$A$:\n",
    "$$\n",
    "A =\n",
    "  \\begin{bmatrix} Q_1 & Q_2 \\end{bmatrix}\n",
    "  \\begin{bmatrix} R_1 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "where $Q_2$ is a basis for the null space of $A^T$. The set of solutions satisfying\n",
    "the constraints $A^T x = b$ is\n",
    "$$\n",
    "  \\Omega = \\{ u + Q_2 y : y \\in {\\mathbb{R}}^{(n-m)}, u = Q_1 R_1^{-T} b \\};\n",
    "$$\n",
    "here $u$ is a *particular solution* to the problem. If we substitute\n",
    "this parameterization of $\\Omega$ into the objective, we have the\n",
    "unconstrained problem \n",
    "$$\n",
    "  \\mbox{minimize } \\phi(u + Q_2 y).\n",
    "$$\n",
    "While we can substitute directly to get a quadratic objective in terms of $y$, \n",
    "it is easier (and a good exercise in remembering the chain rule) to compute\n",
    "the stationary equations\n",
    "$$\\begin{aligned}\n",
    "  0\n",
    "  &= \\nabla_y \\phi(u + Q_2 y) \n",
    "  = \\left(\\frac{\\partial x}{\\partial y}\\right)^T \\nabla_x \\phi(u+Q_2 y) \\\\\n",
    "  &= Q_2^T (H (Q_2 y + u) - d) \n",
    "  = (Q_2^T H Q_2) y - Q_2^T (d-Hu).\n",
    "\\end{aligned}$$\n",
    "In general, even if $A$ is sparse, $Q_2$ may be dense, and so even if $H$ is dense,\n",
    "we find that $Q_2^T H Q_2$ is dense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the 2-by-2 problem via a null-space approach\n",
    "\n",
    "F = qr(A)\n",
    "Q = F.Q * I\n",
    "Q1 = Q[:,[1]]\n",
    "Q2 = Q[:,[2]]\n",
    "\n",
    "u = Q1*(F.R'\\b)\n",
    "H22 = Q2'*H*Q2\n",
    "r2  = Q2'*(d-H*u)\n",
    "y   = H22\\r2\n",
    "x   = u + Q2*y\n",
    "\n",
    "xx = range(-3, 3, length=100)\n",
    "plot(xx, xx, (x,y) -> ϕ1([x; y]), st=:contour, legend=false)\n",
    "plot!(xx, 1.0 .- xx, linewidth=2)\n",
    "plot!([u[1]], [u[2]], markercolor=:white, marker=true)\n",
    "plot!([x[1]], [x[2]], marker=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a particular solution and a null space basis via QR is great for numerical\n",
    "stability, but it may not be ideal when the matrices involved are sparse or structured.\n",
    "An alternative is to use a sparse LU factorization of $A^T$:\n",
    "$$\n",
    "  P A^T Q = L \\begin{bmatrix} U_1 U_2 \\end{bmatrix}.\n",
    "$$\n",
    "where the $U_1$ submatrix is upper triangular.  A particular solution is then\n",
    "$$\n",
    "  x = Q \\begin{bmatrix} U_1^{-1} L^{-1} P b \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "and the null space is spanned by\n",
    "$$\n",
    "  Q^T \n",
    "  \\begin{bmatrix}\n",
    "    -U_1^{-1} U_2 \\\\\n",
    "    I\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "This reformulation may be particularly attractive if $A$ is large, sparse, and close\n",
    "to square.  Note that pivoting on rectangular constraint matrices needs to be done\n",
    "carefully, e.g. using so-called *rook pivoting* strategies that maintain numerical\n",
    "stability on full-rank matrices with rank-deficient submatrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected gradient and conjugate gradients\n",
    "\n",
    "The *projected gradient* is a variant of gradient descent for constrained problem.  One assumes that we have\n",
    "a projection operator $P$ such that $P(x)$ is the closest point to $x$ satisfying the constraint; the iteration\n",
    "is then\n",
    "$$\n",
    "  x_{k+1} = P\\left( x_k - \\alpha_k \\nabla \\phi(x_k) \\right).\n",
    "$$\n",
    "That is, we take an (unconstrained) gradient descent step, then project back to satisfy the constraint.\n",
    "It's an easy enough method to code, provided you have the projection $P$.\n",
    "\n",
    "For our linear equality constraints the projection can be computed by a least squares type of solve:\n",
    "$$\\begin{aligned}\n",
    "  P(x) &= x + A(A^T A)^{-1} (b-A^T x) \\\\\n",
    "       &= (A^T)^\\dagger b + (I-AA^\\dagger) x \\\\\n",
    "       &= (A^T)^\\dagger b + (I-\\Pi) x\n",
    "\\end{aligned}$$\n",
    "Note that $(A^T)^\\dagger b$ is the minimal norm solution to the constraint equation, and the range space of\n",
    "$I-\\Pi = I-AA^\\dagger$ is the null space of $A^T$, so this is similar to the picture we saw with the constraint\n",
    "elimination approach.  And, of course, the gradient in this case is just the residual $r_k = Hx_k - d$.\n",
    "\n",
    "If we start with a point $x_0$ that is consistent with the constraints, then each successive\n",
    "point remains on our linear constraint surface; in this case, we can simplify the iteration to\n",
    "$$\n",
    "  x_{k+1} = x_k - \\alpha_k (I-\\Pi) r_k\n",
    "$$\n",
    "This is a stationary iteration for the underdetermined consistent equation\n",
    "$$\n",
    "  (I-\\Pi) (Hx_k-d) = 0.\n",
    "$$\n",
    "\n",
    "Unfortunately, the projected gradient iteration may converge rather slowly.  A tempting thought is to\n",
    "use a scaled version of the gradient, but the naive version of this iteration will in general converge\n",
    "to the wrong point unless the projection operator is re-defined in terms of the distance associated with\n",
    "the same scaling matrix.\n",
    "\n",
    "If the relevant projection is available, a potentially more attractive route for this problem \n",
    "is to write $x = u + z$ for some particular solution $u$ (as in the null space approach) and then\n",
    "use a method like conjugate gradients on the system\n",
    "$$\n",
    "  (I-\\Pi) H (I-\\Pi) z = (I-\\Pi) (d - Hu)\n",
    "$$\n",
    "It turns out that the Krylov subspace generated by this iteration remains consistent with the constraint,\n",
    "and so -- somewhat surprisingly at first glance -- the method continues to work even\n",
    "though $(I-\\Pi) H (I-\\Pi)$ is singular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalties and conditioning\n",
    "\n",
    "Now consider a penalty formulation of the same equality-constrained\n",
    "optimization function, where the penalty is quadratic:\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) + \\frac{1}{2\\mu} \\|A^T x-b\\|^2.\n",
    "$$\n",
    "In fact, the augmented objective function is again quadratic, and the critical\n",
    "point equations are\n",
    "$$\n",
    "  (H + \\mu^{-1} AA^T) x = d + \\mu^{-1} A b.\n",
    "$$\n",
    "If $\\mu$ is small enough and the equality-constrained quadratic program (QP)\n",
    "has a minimum, then $H+\\mu^{-1} AA^T$ is guaranteed to be positive definite.\n",
    "This means we can solve via Cholesky; or (if the linear system is larger)\n",
    "we might use conjugate gradients.\n",
    "\n",
    "We can analyze this more readily by changing to the $Q$ basis from the QR\n",
    "decomposition of $A$ that we saw in the constraint elimination approach:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  Q_1^T H Q_1 + \\mu^{-1} R_1 R_1^T & Q_1^T H Q_2 \\\\\n",
    "  Q_2^T H Q_1 & Q_2^T H Q_2\n",
    "\\end{bmatrix}\n",
    "(Q^T x) =\n",
    "\\begin{bmatrix}\n",
    "  Q_1^T d + \\mu^{-1} R_1 b \\\\\n",
    "  Q_2^T d\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Taking a Schur complement, we have\n",
    "$$\n",
    "(\\mu^{-1} R_1 R_1^T + F)(Q_1^T x) = \\mu^{-1} R_1 b - g\n",
    "$$\n",
    "where\n",
    "$$\\begin{aligned}\n",
    "  F &= Q_1^T H Q_1 - Q_1^T H Q_2 (Q_2^T H Q_2)^{-1} Q_2^T H Q_1 \\\\\n",
    "  g &= [I - Q_1^T H Q_2 (Q_2^T H Q_2)^{-1} Q_2^T] d\n",
    "\\end{aligned}$$\n",
    "As $\\mu \\rightarrow 0$, the first row of equations is dominated by the\n",
    "$\\mu^{-1}$ terms, and we are left with\n",
    "$$\n",
    "  R_1 R_1^T (Q_1^T x) - R_1 b \\rightarrow 0\n",
    "$$\n",
    "i.e. $Q_1 Q_1^T x$ is converging to $u = Q_1 R_1^{-T} b$, the particular\n",
    "solution that we saw in the case of constraint elimination. Plugging this\n",
    "behavior into the second equation gives\n",
    "$$\n",
    "  (Q_2^T H Q_2) (Q_2^T x) - Q_2^T (d-Hu) \\rightarrow 0,\n",
    "$$\n",
    "i.e. $Q_2^T x$ asymptotically behaves like $y$ in the previous example.\n",
    "We need large $\\mu$ to get good results if the constraints are ill-posed or if\n",
    "$Q_2^T H Q_2$ is close to singular. But in general the condition number\n",
    "scales like $O(\\mu^{-1})$, and so large values of $\\mu$ correspond to\n",
    "problems that are numerically unattractive, as they may lead to large\n",
    "errors or (for iterative solvers) to slow convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the solve with a moderate penalty\n",
    "\n",
    "μ = 1e-4\n",
    "xhat = (H+A*A'/μ)\\(d+A*b[1]/μ)\n",
    "println(\"Error at μ=$μ: $(xhat-x)\")\n",
    "\n",
    "xx = range(-3, 3, length=100)\n",
    "plot(xx, xx, (x,y) -> ϕ1([x; y]), st=:contour, legend=false)\n",
    "plot!(xx, 1.0 .- xx, linewidth=2)\n",
    "plot!([u[1]], [u[2]], markercolor=:white, marker=true)\n",
    "plot!([xhat[1]], [xhat[2]], marker=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary penalty to illustrate issues -- uniform improvement with smaller penalty until ill-conditioning kills us\n",
    "μs = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14]\n",
    "errs = []\n",
    "for μ in μs\n",
    "    xhat = (H+A*A'/μ)\\(d+A*b[1]/μ)\n",
    "    push!(errs, norm(xhat-x))\n",
    "end\n",
    "plot(μs, errs, xscale=:log10, yscale=:log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrange multipliers and KKT systems\n",
    "\n",
    "The KKT conditions for our equality-constrained problem say that the\n",
    "gradient of $$L(x,\\lambda) = \\phi(x) + \\lambda^T (A^T x-b)$$ should be\n",
    "zero. In matrix form, the KKT system (saddle point system)\n",
    "$$\\begin{bmatrix}\n",
    "    H & A \\\\\n",
    "    A^T & 0\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix} x \\\\ \\lambda \\end{bmatrix} =\n",
    "  \\begin{bmatrix} d \\\\ b \\end{bmatrix}.$$ If $A$ and $H$ are\n",
    "well-conditioned, then so is this system, so there is no bad numerical\n",
    "behavior. The system also retains whatever sparsity was present in the\n",
    "original system matrices $H$ and $A$. However, adding the Lagrange\n",
    "multipliers not only increases the number of variables, but the extended\n",
    "system lacks any positive definiteness that $H$ may have.\n",
    "\n",
    "When there are relatively few constraints and a fast solver with $H$\n",
    "is available, an attractive way to solve this KKT system is the so-called\n",
    "range-space method, which we recognize as just block Gaussian elimination:\n",
    "$$\\begin{aligned}\n",
    "  A^T H^{-1} A \\lambda &= A^T H^{-1} d - b \\\\\n",
    "  x = H^{-1} (d - A\\lambda)\n",
    "\\end{aligned}$$\n",
    "Rewritten as we might implement it, we have\n",
    "$$\\begin{aligned}\n",
    "  H x_0 &= d \\\\\n",
    "  H Y   &= A \\\\\n",
    "  (A^T Y) \\lambda &= A^T x_0 - b \\\\\n",
    "  x &= x_0 - Y \\lambda\n",
    "\\end{aligned}$$\n",
    "\n",
    "The KKT system is closely related to the penalty formulation that we saw\n",
    "in the previous subsection, in that if we use Gaussian elimination to\n",
    "remove the variable $\\lambda$ in $$\\begin{bmatrix}\n",
    "    H & A \\\\\n",
    "    A^T & -\\mu I\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix} \\hat{x} \\\\ \\lambda \\end{bmatrix} =\n",
    "  \\begin{bmatrix} d \\\\ b \\end{bmatrix},$$ we have the Schur complement\n",
    "system $$(H+\\mu^{-1} AA^T) \\hat{x} = d + \\mu^{-1} A b,$$ which is\n",
    "identical to the stationary point condition for the quadratically\n",
    "penalized objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xλ = [H A; A' 0.0] \\ [d; b]\n",
    "println(\"Error: $(x-xλ[1:end-1])\")\n",
    "println(\"λ = $(xλ[end])\")\n",
    "println(\"∇ϕ(x) = $(H*xλ[1:end-1]-d)\")\n",
    "println(\"λ × ∇c(x) = $(xλ[end]) × $A = $(xλ[end]*A)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the constrained stationarity condition\n",
    "$$\n",
    "  \\nabla \\phi(x_*) + \\lambda \\nabla c(x_*) = 0,\n",
    "$$\n",
    "and we can use this to estimate the Lagrange multipliers from an approximation via a penalty method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = 1e-4\n",
    "xhat = (H+A*A'/μ)\\(d+A*b[1]/μ)\n",
    "r = H*xhat-d\n",
    "println(\"λ ≈ $(-norm(r)^2/(A'*r))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uzawa iteration\n",
    "\n",
    "Block Gaussian elimination is an attractive approach when we have a fast solver for $H$ and there are not\n",
    "too many constraints.  When there are a relatively large number of constraints, we might seek an alternate\n",
    "method.  One such method is the *Uzawa iteration*\n",
    "$$\\begin{aligned}\n",
    "  H x_{k+1} &= d - A \\lambda_k \\\\\n",
    "  \\lambda_{k+1} &= \\lambda_{k} + \\omega (A^T x_{k+1}-b)\n",
    "\\end{aligned}$$\n",
    "where $\\omega > 0$ is a relaxation parameter.  We can eliminate $x_{k+1}$ to get the iteration\n",
    "$$\n",
    "  \\lambda_{k+1} \n",
    "  = \\lambda_k + \\omega (A^T H^{-1} (d-A\\lambda_k) - b)\n",
    "  = (I-\\omega A^T H^{-1} A) \\lambda_k + \\omega (A^T H^{-1} d  - b),\n",
    "$$\n",
    "which is a Richardson iteration on the Schur complement equation $(A^T H^{-1} A) \\lambda = A^T H^{-1} d - b$.\n",
    "We can precondition and accelerate the Uzawa iteration in a variety of ways, as you might guess from our earlier\n",
    "discussion of iterative methods for solving linear systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting the Lagrangian\n",
    "\n",
    "From a solver perspective, the block 2-by-2 structure of the KKT system\n",
    "looks highly attractive. Alas, we do *not* require that $H$ be\n",
    "positive definite, nor even that it be nonsingular; to have a unique\n",
    "global minimum, we only need positive definiteness of the projection of\n",
    "$H$ onto the null space (i.e. $Q_2^T H Q_2$ should be positive\n",
    "definite). This means we cannot assume that (for example) $H$ will admit\n",
    "a Cholesky factorization.\n",
    "\n",
    "The augmented Lagrangian approach can be seen as solving the constrained\n",
    "system\n",
    "$$\n",
    "  \\mbox{minimize } \\frac{1}{2} x^T H x - d^T x + \\frac{1}{2\\mu} \\|A^T x-b\\|^2\n",
    "  \\mbox{ s.t. } A^T x = b.\n",
    "$$\n",
    "The term penalizing nonzero $\\|A^T x-b\\|$ is, of course, irrelevant at points \n",
    "satisfying the constraint $A^T x = b$. Hence, the constrained minimum for this\n",
    "augmented objective is identical to the constrained minimum of the original objective.\n",
    "However, if the KKT conditions for the modified objective take the form\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    H+\\mu^{-1}AA^T & A \\\\\n",
    "    A^T & 0\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix} x \\\\ \\lambda \\end{bmatrix} =\n",
    "  \\begin{bmatrix} d + \\mu^{-1} A b \\\\ b \\end{bmatrix}.\n",
    "$$\n",
    "Now we do not necessarily need to drive $\\mu$ to zero to obtain a good solution;\n",
    "but by choosing $\\mu$ small enough, we can ensure that $H + \\mu^{-1} AA^T$\n",
    "is positive definite (assuming that the problem is convex subject to the\n",
    "constraint).  This can be helpful when we want to use a Cholesky factorization\n",
    "or a method like CG, but the original $H$ matrix is indefinite or singular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a non-positive-definite problem for linearly-constrained QP (2D so that we can plot)\n",
    "H = [4.0  1.0 ;\n",
    "     1.0  -1.0 ]\n",
    "d = [0.5 ; -2.0]\n",
    "A = [1.0 ; 1.0]\n",
    "b = 1.0\n",
    "\n",
    "ϕ2(xy) = xy'*H*xy/2 - xy'*d\n",
    "c2(xy) = A'*xy - b\n",
    "ϕ3(xy) = ϕ2(xy) + 3*norm(c2(xy))^2\n",
    "xy_sol = [H A; A' 0.0] \\ [d; b]\n",
    "\n",
    "xx = range(-3, 3, length=100)\n",
    "plot(xx, xx, (x,y) -> ϕ2([x; y]), st=:contour, legend=false)\n",
    "plot!(xx, xx, (x,y) -> ϕ3([x; y]), st=:contour, linestyle=:dash)\n",
    "plot!(xx, 1.0 .- xx, linewidth=2)\n",
    "plot!([xy_sol[1]], [xy_sol[2]], marker=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: do we have a constrained min (vs max or saddle)?\n",
    "plot(xx, [ϕ2([x; 1.0-x]) for x in xx], legend=false)\n",
    "plot!(xx, [ϕ3([x; 1.0-x]) for x in xx], linestyle=:dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the solution via method of Lagrange multipliers\n",
    "xλ = [H A; A' 0.0] \\ [d; b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the Lagrangian so the (1,1) submatrix is positive definite\n",
    "σ = 2.0\n",
    "xλ_augmented = [H+A*A'/σ A; A' 0.0] \\ [d+A*b[1]/σ; b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic programs with inequality constraints\n",
    "\n",
    "We now consider a quadratic objective with linear inequality\n",
    "constraints:\n",
    "$$\\begin{aligned}\n",
    "  \\phi(x) &= \\frac{1}{2} x^T H x - x^T d \\\\\n",
    "  c(x) &= A^T x-b \\leq 0,\n",
    "\\end{aligned}$$ \n",
    "where\n",
    "$H \\in {\\mathbb{R}}^{n \\times n}$ is symmetric and positive definite,\n",
    "$A \\in {\\mathbb{R}}^{n \\times m}$ with $m < n$, and\n",
    "$b \\in {\\mathbb{R}}^m$. The KKT conditions for this problem are\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda &= 0 \\\\\n",
    "  A^T x-b & \\leq 0 \\\\\n",
    "  \\lambda & \\geq 0 \\\\\n",
    "  \\lambda_i (A^T x-b)_i &= 0.\n",
    "\\end{aligned}$$\n",
    "The *active set* is the set of $i$ such that $(A^T x-b)_i = 0$. We assume\n",
    "that the active columns of $A$ are always linearly independent\n",
    "(e.g. $0 \\leq x_i$ and $x_i \\leq 1$ can co-exist, but it is not OK to\n",
    "have both $x_i \\leq 1$ and $x_i \\leq 2$).\n",
    "\n",
    "Examples are always good, as are pictures.  We will borrow the following\n",
    "2D example from Nocedal and Wright (Example 16.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective in Nocedal and Wright: ϕ(x) = (x[1]-1.0)^2 + (x[2]-2.5)^2\n",
    "#   We will get rid of a constant term to get it to our usual form (and scale by 1/2)\n",
    "#\n",
    "H = [1.0 0.0; 0.0 1.0]\n",
    "d = [1.0; 2.5]\n",
    "\n",
    "# Constraints per Nocedal and Wright -- we rewrite so the inequality goes the other way\n",
    "#  x1 - 2 x2 + 2 ≥ 0\n",
    "# -x1 - 2 x2 + 6 ≥ 0\n",
    "# -x1 + 2 x2 + 2 ≥ 0\n",
    "#  x1 ≥ 0\n",
    "#  x2 ≥ 0\n",
    "#\n",
    "A = [-1.0  2.0 ;\n",
    "      1.0  2.0 ;\n",
    "      1.0 -2.0 ;\n",
    "     -1.0  0.0 ;\n",
    "      0.0 -1.0 ]'\n",
    "b = [2.0; 6.0; 2.0; 0.0; 0.0]\n",
    "\n",
    "# Draw a plot of the quadratic and the constraints\n",
    "function plot_ex16_3()\n",
    "    q(x,y) = (x-1.0)^2 + (y-2.5)^2\n",
    "    corners = [0.0 0.0 ;\n",
    "               2.0 0.0 ;\n",
    "               4.0 1.0 ;\n",
    "               2.0 2.0 ;\n",
    "               0.0 1.0 ]\n",
    "    xx = range(-1.0, 4.0, length=101)\n",
    "    p = plot(corners[:,1], corners[:,2], st=:shape)\n",
    "    plot!(xx, xx, q, st=:contour, legend=false)\n",
    "    p\n",
    "end\n",
    "\n",
    "plot_ex16_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An active set approach\n",
    "\n",
    "At the $k$th step in an active set QP solver, we update an iterate $x^k$\n",
    "approximating the constrained minimizer *and* we update a\n",
    "corresponding working set $\\mathcal{W}^k$ approximating the active set.\n",
    "A step of this solver looks like:\n",
    "\n",
    "1.  Choose a step $p^k$ by minimizing the quadratic form assuming the\n",
    "    constraints in $\\mathcal{W}^k$ are the active constraints. This\n",
    "    gives an equality-constrained subproblem.\n",
    "\n",
    "2.  If $p^k$ is zero, then\n",
    "\n",
    "    1.  Compute the Lagrange multipliers associated with the set\n",
    "        $\\mathcal{W}^k$.\n",
    "\n",
    "    2.  If all the multipliers are non-negative, terminate.\n",
    "\n",
    "    3.  Otherwise, let $\\lambda_j$ be the most negative multiplier, and\n",
    "        set $\\mathcal{W}^{k+1} = \\mathcal{W}^k \\setminus \\{ j \\}$\n",
    "\n",
    "3.  Otherwise $p^k \\neq 0$.\n",
    "\n",
    "    1.  Advance $x^{k+1} = x^k + \\alpha_k p^k$ where the step length\n",
    "        $\\alpha_k$ is the largest allowed value (up to one) such that\n",
    "        $x^{k+1}$ is feasible.\n",
    "\n",
    "    2.  If $\\alpha_k < 1$, then there is (at least) one *blocking\n",
    "        constraint* $j$ such that $(A^T x^{k+1}-b)_j = 0$ and\n",
    "        $j \\not \\in \\mathcal{W}^k$. Update\n",
    "        $\\mathcal{W}^{k+1} = \\mathcal{W}^k \\cup \\{ j \\}$.\n",
    "\n",
    "If we do not attempt any particular efficiency, this is mostly straightforward to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function qp_as(x0, H, d, A, b; ptol=1e-8, W0=[], nsteps=100, monitor=(x, W)->nothing)\n",
    "\n",
    "    n = length(x0)\n",
    "    m = length(b)\n",
    "    W = zeros(Bool, m)\n",
    "    \n",
    "    x = copy(x0)\n",
    "    p = zeros(n)\n",
    "    λ = zeros(m)\n",
    "    W[W0] .= true\n",
    "    monitor(x, W)\n",
    "\n",
    "    # Compute Cholesky factorization for range space solver\n",
    "    F = cholesky(H)\n",
    "    L = F.L\n",
    "    Y = L\\A\n",
    "    c = L\\d\n",
    "    \n",
    "    for k = 1:nsteps\n",
    "        \n",
    "        ## Solve the equality constrained subproblem (range space method)        \n",
    "        λ[:] .= 0.0\n",
    "        λ[W] = ( Y[:,W]'*Y[:,W] )\\( Y[:,W]'*c - b[W] )\n",
    "        p[:] = L'\\(c-Y[:,W]*λ[W])-x\n",
    "        \n",
    "        if norm(p) < ptol\n",
    "            \n",
    "            # Find most negative multiplier (if there is one)\n",
    "            minλ = 0.0\n",
    "            j = 0\n",
    "            for k = 1:m\n",
    "                if λ[k] < minλ\n",
    "                    minλ = λ[k]\n",
    "                    j = k\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if j == 0\n",
    "                return x      # All multipliers non-negative, done!\n",
    "            else\n",
    "                W[j] = false  # Release jth constraint\n",
    "            end\n",
    "\n",
    "        else\n",
    "            \n",
    "            # Figure out step (and any blocking constraint)\n",
    "            α = 1.0\n",
    "            r = b-A'*x\n",
    "            u = A'*p\n",
    "            blocking_idx = 0\n",
    "            for k = 1:m\n",
    "                if !(k in W) && (α*u[k] > r[k])\n",
    "                    α = r[k]/u[k]\n",
    "                    blocking_idx = k\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            # Take step and update list of active constraints\n",
    "            x[:] += α*p\n",
    "            if blocking_idx > 0\n",
    "                W[blocking_idx] = true\n",
    "            end\n",
    "            monitor(x, W)\n",
    "\n",
    "        end\n",
    "    end\n",
    "    error(\"Did not converge after $nsteps steps\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhist = []\n",
    "xsol = qp_as([2.0; 0.0], H, d, A, b, W0=[3 5], monitor=(x, W) -> push!(xhist, copy(x)))\n",
    "println(\"x = $xsol\")\n",
    "\n",
    "p = plot_ex16_3()\n",
    "plot!([x[1] for x in xhist], [x[2] for x in xhist], marker=true, linewidth=3, linestyle=:dash, color=:black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks about this strategy are in order:\n",
    "\n",
    "-   The strategy is guaranteed not to cycle — the working set at any\n",
    "    given iterate is distinct from the working set at any other iterate.\n",
    "    Assuming the steps are computed exactly (via Newton), the iteration\n",
    "    converges in a finite number of steps. That said, there are an\n",
    "    exponential number of working sets; and, as with the simplex method\n",
    "    for linear programming, there are examples where the algorithm may\n",
    "    have exponential complexity because of the cost of exploring all the\n",
    "    working set. But, as with the simplex method, this is not the common\n",
    "    case.\n",
    "\n",
    "-   The strategy only changes the working set by adding or removing one\n",
    "    constraint at a time. Hence, if $\\mathcal{A}$ is the true active\n",
    "    set, the number of steps required is at least\n",
    "    $|\\mathcal{W}^0| + |\\mathcal{A}| - 2|\\mathcal{W}^0 \\cap \\mathcal{A}|$.\n",
    "    This is bad news if there are many possible constraints and we lack\n",
    "    a good initial guess as to which ones will be active.\n",
    "\n",
    "-   If we compute the steps $p^k$ as described above, the cost per step\n",
    "    (after an initial factorization of the Hessian and triangular solves on the constraints)\n",
    "    would appear to be $O(n^2+n|\\mathcal{W}^k|^2)$. In practice, though,\n",
    "    each linear system differs from the previous system only through the\n",
    "    addition or deletion of a constraint. If we are clever with our\n",
    "    numerical linear algebra, and re-use the factorization work already\n",
    "    invested through updating and downdating, we can reduce the cost per\n",
    "    step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barriers: hard and soft\n",
    "\n",
    "Before we proceed, a word is in order about the relationship between\n",
    "Lagrange multipliers and barriers or penalties. To be concrete, let us\n",
    "consider the inequality-constrained problem\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) \\mbox{ s.t. } c(x) \\leq 0,\n",
    "$$ \n",
    "where\n",
    "$c : {\\mathbb{R}}^n \\rightarrow {\\mathbb{R}}^m$ with $m < n$, and the\n",
    "inequality should be interpreted elementwise. In a barrier formulation,\n",
    "we approximate the problem by problems of the form\n",
    "$$\n",
    "  \\mbox{minimize } \\phi(x) - \\mu \\sum_{j=1}^m \\log(-c_j(x)),\n",
    "$$\n",
    "where the second term shoots to infinity as $c_j(x) \\rightarrow 0$; \n",
    "but for any fixed $c_j(x) < 0$ it becomes negligible once $\\mu$ is small enough.\n",
    "Differentiating this objective gives us the critical point equations\n",
    "$$\n",
    "  \\nabla \\phi(\\hat{x}(\\mu))\n",
    "  -\\sum_{j=1}^m \\frac{\\mu}{c_j(\\hat{x}(\\mu))} \\nabla c_j(\\hat{x}(\\mu)) = 0.\n",
    "$$\n",
    "By way of comparison, if we were to try to exactly optimize this\n",
    "inequality constrained problem, we would want to satisfy the KKT\n",
    "conditions\n",
    "$$\\begin{aligned}\n",
    "  \\nabla \\phi(x) + \\nabla c(x) \\lambda &= 0 \\\\\n",
    "  c(x) & \\leq 0 \\\\\n",
    "  \\lambda & \\geq 0 \\\\\n",
    "  \\lambda_j(x) c_j(x) &= 0.\n",
    "\\end{aligned}$$\n",
    "Comparing the two, we see that the quantities \n",
    "$\\hat{\\lambda}_j(\\mu) \\equiv -\\mu/c_j(x_*(\\mu))$\n",
    "should approximate the Lagrange multipliers: they play the same role in\n",
    "the equation involving the gradient of $\\phi$, they are always positive\n",
    "for $\\mu > 0$, and $\\hat{\\lambda}_j(x_*(\\mu)) \\rightarrow 0$ provided\n",
    "$c_j(x_*(\\mu)) \\not \\rightarrow 0$.\n",
    "\n",
    "I like to think of barriers and penalties in physical terms as being\n",
    "like slightly flexible walls. In real life, when you push on a wall,\n",
    "however stiff, there is a little bit of give. What we see as an opposing\n",
    "force generated by a rigid wall is really associated with that little\n",
    "bit of elastic give. But a good idealization is that of a perfectly\n",
    "rigid wall, which does not give at all. Instead, it responds to conctact\n",
    "with exactly the amount of force normal to the wall surface that is\n",
    "required to counter any force pushing into the wall. That\n",
    "equal-and-opposite force is exactly what is captured by Lagrange\n",
    "multipliers, where the very stiff elastic response is captured by the\n",
    "barrier or penalty formulation, with the parameter $\\mu$ representing\n",
    "the compliance of the barrier (inverse stiffness).\n",
    "\n",
    "The weakness of a penalty or barrier approach is two-fold: if $\\mu$ is\n",
    "far from zero, we have a thick and spongy barrier (a poor approximation\n",
    "to the infinitely rigid case); whereas if $\\mu$ is close to zero, we\n",
    "have a nearly-rigid barrier, but the Hessian of the augmented barrier\n",
    "function becomes very ill-conditioned, scaling like $\\mu^{-1}$. In\n",
    "contrast, with a Lagrange multiplier formulation, we have a perfect\n",
    "barrier and no problems with ill-conditioning, but at the cost of having\n",
    "to explicitly determine whether the optimum is at one or more of the\n",
    "constraint surfaces, and also what “contact forces” are needed to\n",
    "balance the negative gradient of $\\phi$ that pushes into the barrier.\n",
    "\n",
    "Several modern algorithmic approaches, such as augmented Lagrangian and\n",
    "interior point methods, get the best of both perspectives by combining a\n",
    "penalty or barrier term with a Lagrange multiplier computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An interior point strategy\n",
    "\n",
    "Having touched on the relation between Lagrange multipliers and\n",
    "logarithmic barriers, let us now turn to an interior point method for\n",
    "quadratic programming. We start by rewriting the constraints\n",
    "$A^Tx - b \\leq 0$ in terms of an extra set of slack variables:\n",
    "$$y = b-A^Tx \\geq 0.$$ With this definition, we write the KKT conditions\n",
    "as\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda & = 0 \\\\\n",
    "  A^T x-b+y &= 0 \\\\\n",
    "  \\lambda_i y_i &= 0 \\\\\n",
    "  y_i, \\lambda_i & \\geq 0.\n",
    "\\end{aligned}$$\n",
    "Interior point methods solve this system by applying Newton-like iterations \n",
    "to the three equations, while at the same time ensuring that the inequalities\n",
    "are enforced strictly at every step (that is, every step is interior to the feasible\n",
    "domain).\n",
    "\n",
    "Compare this to the critical point conditions for the barrier problem\n",
    "$$\n",
    "  \\mbox{minimize } \\frac{1}{2} x^T H x - x^T d - \\gamma \\sum_{j=1}^m \\log(y_j)\n",
    "$$\n",
    "for some small value of the barrier parameter $\\gamma$, where we note\n",
    "that\n",
    "$$\n",
    "  \\nabla_x \\left( -\\gamma \\sum_{j=1}^n \\log(y_j) \\right) =\n",
    "  A \\hat{\\lambda}, \\quad \\hat{\\lambda}_j = \\frac{\\gamma}{y_j}\n",
    "$$\n",
    "and we can rewrite this system as\n",
    "$$\\begin{aligned}\n",
    "  Hx - d + A\\lambda &= 0 \\\\\n",
    "  A^T x - b + y &= 0 \\\\\n",
    "  y_i \\lambda_i - \\gamma &= 0.\n",
    "\\end{aligned}$$\n",
    "Typical interior point methods take guarded Newton steps (or Newton-like steps)\n",
    "on this system of equations, which can be regarded as a relaxation of the KKT\n",
    "conditions or as a critical point of a barrier formulation.  The path traced out\n",
    "as $\\mu$ varies is known as the \"central path.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function barrier_qp(x0, H, d, A, b, γ; nsteps=20, ptol=1e-8)\n",
    "\n",
    "    n = length(d)\n",
    "    m = length(b)\n",
    "    σ = 0.5\n",
    "\n",
    "    x = copy(x0)\n",
    "    y = b-A'*x\n",
    "    λ = γ./y\n",
    "    \n",
    "    F(x, y, λ) = [H*x - d + A*λ; \n",
    "                  A'*x - b + y;\n",
    "                  y.*λ .- γ]\n",
    "    J(x, y, λ) = [H          zeros(n,m)  A;\n",
    "                  A'         I           zeros(m,m);\n",
    "                  zeros(m,n) diagm(λ)    diagm(y)]\n",
    "    \n",
    "    α = 1.0    \n",
    "    p = -(J(x, y, λ) \\ F(x, y, λ))\n",
    "    for k = 1:nsteps\n",
    "        xnew = x + α*p[1:n]\n",
    "        if all(A'*xnew-b .<= 0.0)\n",
    "            x = xnew\n",
    "            y += α*p[n+1:n+m]\n",
    "            λ += α*p[n+m+1:end]\n",
    "            if α == 1.0 && norm(p) < ptol\n",
    "                return x, λ\n",
    "            end\n",
    "            α = 1.0\n",
    "            p = -(J(x, y, λ) \\ F(x, y, λ))\n",
    "        else\n",
    "            α /= 2.0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    error(\"Did not converge in $nsteps steps\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2.0; 1.0]\n",
    "\n",
    "p = plot_ex16_3()\n",
    "plot!([x[1]], [x[2]], marker=true, color=:black)\n",
    "for s = 1:10\n",
    "    x, λ = barrier_qp(x, H, d, A, b, 2.0^(1-s))\n",
    "    plot!([x[1]], [x[2]], marker=true, color=:black)\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\gamma$ is adjusted dynamically during the solve, and is\n",
    "usually written as $\\gamma = \\sigma \\mu$ where $\\sigma \\in [0,1]$ is the\n",
    "centering parameters and $\\mu = y^T \\lambda / m$ is the\n",
    "*complimentarity measure*, which should go to zero as we approach a\n",
    "problem solution.  Getting all the details right is somewhat complicated,\n",
    "though, and we recommend using a package written by someone with some\n",
    "expertise.\n",
    "\n",
    "Interior point methods avoid the problem of having to do a combinatorial\n",
    "search to figure out the correct active set. At the same time, active\n",
    "set methods may be more efficient for problems where we have a good\n",
    "initial guess at the active set. Neither approach is universally\n",
    "preferable.  Indeed, it is possible to take a hybrid approach where an\n",
    "interior point method (or something similar) is used to estimate \n",
    "which constraints are actually active, and then an active set method\n",
    "serves to \"clean up\" the solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
